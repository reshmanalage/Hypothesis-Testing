{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11470311",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' A F&B manager wants to determine whether there is \n",
    "any significant difference in the diameter of the \n",
    "cutlet between two units. A randomly selected sample\n",
    "of cutlets was collected from both units and measured?\n",
    "Analyze the data and draw inferences at 5% significance level. \n",
    "Please state the assumptions and tests that you carried out\n",
    "to check validity of the assumptions.\n",
    "\n",
    "\n",
    "     Minitab File : Cutlets.mtw\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "622fe577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unit A  Unit B\n",
      "0   6.8090  6.7703\n",
      "1   6.4376  7.5093\n",
      "2   6.9157  6.7300\n",
      "3   7.3012  6.7878\n",
      "4   7.4488  7.1522\n",
      "5   7.3871  6.8110\n",
      "6   6.8755  7.2212\n",
      "7   7.0621  6.6606\n",
      "8   6.6840  7.2402\n",
      "9   6.8236  7.0503\n",
      "10  7.3930  6.8810\n",
      "11  7.5169  7.4059\n",
      "12  6.9246  6.7652\n",
      "13  6.9256  6.0380\n",
      "14  6.5797  7.1581\n",
      "15  6.8394  7.0240\n",
      "16  6.5970  6.6672\n",
      "17  7.2705  7.4314\n",
      "18  7.2828  7.3070\n",
      "19  7.3495  6.7478\n",
      "20  6.9438  6.8889\n",
      "21  7.1560  7.4220\n",
      "22  6.5341  6.5217\n",
      "23  7.2854  7.1688\n",
      "24  6.9952  6.7594\n",
      "25  6.8568  6.9399\n",
      "26  7.2163  7.0133\n",
      "27  6.6801  6.9182\n",
      "28  6.9431  6.3346\n",
      "29  7.0852  7.5459\n",
      "30  6.7794  7.0992\n",
      "31  7.2783  7.1180\n",
      "32  7.1561  6.6965\n",
      "33  7.3943  6.5780\n",
      "34  6.9405  7.3875\n"
     ]
    }
   ],
   "source": [
    "#import the library\n",
    "import scipy.stats as stats\n",
    "\n",
    "#load the data file\n",
    "import pandas as pd\n",
    "data = pd.read_csv(r\"C:\\Users\\Reshma\\OneDrive\\Desktop\\Data science\\Python Assignmet\\Python Assignment files\\day 3\\Cutlets.csv\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b504efe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names: ['Unit A', 'Unit B']\n",
      "\n",
      "Row Indexes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n"
     ]
    }
   ],
   "source": [
    "# Get the list of column names\n",
    "column_names = data.columns.tolist()\n",
    "print(\"Column Names:\", column_names)\n",
    "\n",
    "# Get the row indexes\n",
    "row_indexes = data.index.tolist()\n",
    "print(\"\\nRow Indexes:\", row_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b9c6264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values in Each Column:\n",
      "Unit A    0\n",
      "Unit B    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values\n",
    "null_values = data.isnull().sum()\n",
    "# Display the count of null values for each column\n",
    "print(\"Null Values in Each Column:\")\n",
    "print(null_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c59ab25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (35, 2)\n"
     ]
    }
   ],
   "source": [
    "# Display the shape of the data\n",
    "print(\"Data Shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91cf2ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (35, 2)\n",
      "\n",
      "Data Description:\n",
      "          Unit A     Unit B\n",
      "count  35.000000  35.000000\n",
      "mean    7.019091   6.964297\n",
      "std     0.288408   0.343401\n",
      "min     6.437600   6.038000\n",
      "25%     6.831500   6.753600\n",
      "50%     6.943800   6.939900\n",
      "75%     7.280550   7.195000\n",
      "max     7.516900   7.545900\n",
      "\n",
      "Entire Dataset:\n",
      "    Unit A  Unit B\n",
      "0   6.8090  6.7703\n",
      "1   6.4376  7.5093\n",
      "2   6.9157  6.7300\n",
      "3   7.3012  6.7878\n",
      "4   7.4488  7.1522\n",
      "5   7.3871  6.8110\n",
      "6   6.8755  7.2212\n",
      "7   7.0621  6.6606\n",
      "8   6.6840  7.2402\n",
      "9   6.8236  7.0503\n",
      "10  7.3930  6.8810\n",
      "11  7.5169  7.4059\n",
      "12  6.9246  6.7652\n",
      "13  6.9256  6.0380\n",
      "14  6.5797  7.1581\n",
      "15  6.8394  7.0240\n",
      "16  6.5970  6.6672\n",
      "17  7.2705  7.4314\n",
      "18  7.2828  7.3070\n",
      "19  7.3495  6.7478\n",
      "20  6.9438  6.8889\n",
      "21  7.1560  7.4220\n",
      "22  6.5341  6.5217\n",
      "23  7.2854  7.1688\n",
      "24  6.9952  6.7594\n",
      "25  6.8568  6.9399\n",
      "26  7.2163  7.0133\n",
      "27  6.6801  6.9182\n",
      "28  6.9431  6.3346\n",
      "29  7.0852  7.5459\n",
      "30  6.7794  7.0992\n",
      "31  7.2783  7.1180\n",
      "32  7.1561  6.6965\n",
      "33  7.3943  6.5780\n",
      "34  6.9405  7.3875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(r\"C:\\Users\\Reshma\\OneDrive\\Desktop\\Data science\\Python Assignmet\\Python Assignment files\\day 3\\Cutlets.csv\")\n",
    "data\n",
    "\n",
    "# Display the shape of the data\n",
    "print(\"Data Shape:\", data.shape)\n",
    "\n",
    "# Display the description of the data\n",
    "print(\"\\nData Description:\")\n",
    "print(data.describe())\n",
    "\n",
    "# Display the entire dataset\n",
    "print(\"\\nEntire Dataset:\")\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34fc1d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normality (Unit A): 0.31997821996861\n",
      "Normality (Unit B): 0.5225029843840996\n",
      "Homogeneity of Variances: 0.417616221250256\n",
      "Two-Sample t-test p-value: 0.47223947245995\n"
     ]
    }
   ],
   "source": [
    "# Separate data for Unit A and Unit B\n",
    "data_unit_a = data['Unit A'].tolist()\n",
    "data_unit_b = data['Unit B'].tolist()\n",
    "\n",
    "# Assumption 1: Normality\n",
    "_, p_value_norm_a = stats.shapiro(data_unit_a)\n",
    "_, p_value_norm_b = stats.shapiro(data_unit_b)\n",
    "\n",
    "# Assumption 2: Homogeneity of Variances\n",
    "_, p_value_var = stats.levene(data_unit_a, data_unit_b)\n",
    "\n",
    "# Print p-values for assumptions check\n",
    "print(\"Normality (Unit A):\", p_value_norm_a)\n",
    "print(\"Normality (Unit B):\", p_value_norm_b)\n",
    "print(\"Homogeneity of Variances:\", p_value_var)\n",
    "\n",
    "# Two-sample t-test\n",
    "_, p_value_ttest = stats.ttest_ind(data_unit_a, data_unit_b)\n",
    "\n",
    "# Print p-value for the t-test\n",
    "print(\"Two-Sample t-test p-value:\", p_value_ttest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a88a4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normality (Unit A): 0.31997821996861\n",
      "Normality (Unit B): 0.5225029843840996\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "# Assuming data is already loaded into 'data' DataFrame\n",
    "_, p_value_norm_a = shapiro(data['Unit A'])\n",
    "_, p_value_norm_b = shapiro(data['Unit B'])\n",
    "\n",
    "print(\"Normality (Unit A):\", p_value_norm_a)\n",
    "print(\"Normality (Unit B):\", p_value_norm_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "637f9bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity of Variances: 0.417616221250256\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import levene\n",
    "\n",
    "_, p_value_var = levene(data['Unit A'], data['Unit B'])\n",
    "\n",
    "print(\"Homogeneity of Variances:\", p_value_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cc7fa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Sample t-test p-value: 0.47223947245995\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Assuming equal variances based on Levene's test\n",
    "_, p_value_ttest = ttest_ind(data['Unit A'], data['Unit B'], equal_var=True)\n",
    "\n",
    "print(\"Two-Sample t-test p-value:\", p_value_ttest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd5be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''If the p-values for normality and homogeneity of variances are greater than\n",
    "0.05, you can proceed with the two-sample t-test.\n",
    "If the p-value for the two-sample t-test is less than 0.05, you reject the null\n",
    "hypothesis and conclude that there is a significant difference in the diameter\n",
    "of cutlets between the two units.'''\n",
    "\n",
    "\n",
    "'''At a 5% significance level, based on the conducted tests, there is\n",
    "no significant difference in the diameter of cutlets between Unit A and Unit B.\n",
    "The assumption of normality and homogeneity of variances is reasonably met.'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd9ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''A hospital wants to determine whether there is any difference in the average\n",
    "Turn Around Time (TAT) of reports of the laboratories on their preferred list.\n",
    "They collected a random sample and recorded TAT for reports of 4 laboratories.\n",
    "TAT is defined as sample collected to report dispatch.\n",
    "   \n",
    "  Analyze the data and determine whether there is any difference in average TAT\n",
    "  among the different laboratories at 5% significance level.\n",
    " \n",
    " \n",
    "    Minitab File: LabTAT.mtw\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8e4e5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (120, 4)\n",
      "\n",
      "Data Description:\n",
      "       Laboratory 1  Laboratory 2  Laboratory 3  Laboratory 4\n",
      "count    120.000000    120.000000    120.000000     120.00000\n",
      "mean     178.361583    178.902917    199.913250     163.68275\n",
      "std       13.173594     14.957114     16.539033      15.08508\n",
      "min      138.300000    140.550000    159.690000     124.06000\n",
      "25%      170.335000    168.025000    188.232500     154.05000\n",
      "50%      178.530000    178.870000    199.805000     164.42500\n",
      "75%      186.535000    189.112500    211.332500     172.88250\n",
      "max      216.390000    217.860000    238.700000     205.18000\n",
      "Updated Data Types:\n",
      "Laboratory 1    float64\n",
      "Laboratory 2    float64\n",
      "Laboratory 3    float64\n",
      "Laboratory 4    float64\n",
      "dtype: object\n",
      "\n",
      "First Few Rows of the Dataset:\n",
      "   Laboratory 1  Laboratory 2  Laboratory 3  Laboratory 4\n",
      "0        185.35        165.53        176.70        166.13\n",
      "1        170.49        185.91        198.45        160.79\n",
      "2        192.77        194.92        201.23        185.18\n",
      "3        177.33        183.00        199.61        176.42\n",
      "4        193.41        169.57        204.63        152.60\n",
      "\n",
      "Column Names: ['Laboratory 1', 'Laboratory 2', 'Laboratory 3', 'Laboratory 4']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(r\"C:\\Users\\Reshma\\OneDrive\\Desktop\\Data science\\Python Assignmet\\Python Assignment files\\day 3\\LabTAT.csv\")  # Adjust the file path as needed\n",
    "\n",
    "# Display the shape of the data\n",
    "print(\"Data Shape:\", data.shape)\n",
    "\n",
    "# Display the description of the data\n",
    "print(\"\\nData Description:\")\n",
    "print(data.describe())\n",
    "\n",
    "# Convert all columns to float\n",
    "data = data.astype(float)\n",
    "\n",
    "# Display the updated data types\n",
    "print(\"Updated Data Types:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"\\nFirst Few Rows of the Dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Display the list of column names\n",
    "column_names = data.columns.tolist()\n",
    "print(\"\\nColumn Names:\", column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31b17695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normality P-values: [0.5507520604202367, 0.8637345311091214, 0.4204747647006849, 0.6619161995270413]\n",
      "Homogeneity of Variances: 0.05161343808309815\n"
     ]
    }
   ],
   "source": [
    "# Check for normality and homogeneity of variances\n",
    "normality_p_values = []\n",
    "for lab in data.columns:\n",
    "    _, p_value_norm = shapiro(data[lab])\n",
    "    normality_p_values.append(p_value_norm)\n",
    "\n",
    "_, p_value_var = levene(*[data[lab] for lab in data.columns])\n",
    "\n",
    "# Print p-values for normality and homogeneity of variances\n",
    "print(\"\\nNormality P-values:\", normality_p_values)\n",
    "print(\"Homogeneity of Variances:\", p_value_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9a89b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Interpretation:\n",
    "\n",
    "For all laboratories, the p-values are greater than 0.05.\n",
    "There is no strong evidence to reject the null hypothesis of normality\n",
    "for any laboratory.\n",
    "You can assume that the data for each laboratory is approximately normally \n",
    "distributed.\n",
    "\n",
    "Interpretation:\n",
    "The p-value is slightly above 0.05, but it's close.\n",
    "There is no strong evidence to reject the null hypothesis of homogeneity of \n",
    "variances.\n",
    "You can assume that the variances of TAT among the laboratories are \n",
    "approximately equal.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11e68e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One-Way ANOVA p-value: 2.1156708949992414e-57\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.stats import f_oneway\n",
    "# One-way ANOVA\n",
    "_, p_value_anova = f_oneway(data['Laboratory 1'], data['Laboratory 2'], data['Laboratory 3'], data['Laboratory 4'])\n",
    "\n",
    "# Print p-value for the ANOVA test\n",
    "print(\"\\nOne-Way ANOVA p-value:\", p_value_anova)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aa74ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The p-value for the one-way ANOVA test is very close to zero \n",
    "(p-value: 2.1156708949992414e-57). \n",
    "This extremely small p-value suggests strong evidence against the \n",
    "null hypothesis. Therefore, you can reject the null hypothesis and \n",
    "conclude that there is a significant difference in the average \n",
    "Turn Around Time (TAT) among at least two laboratories.\n",
    "\n",
    "Conclusion:\n",
    "At a 5% significance level, the one-way ANOVA test indicates that there is a \n",
    "statistically significant difference in average TAT among the laboratories.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c40ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "'''Sales of products in four different regions is tabulated for males and \n",
    "females. Find if male-female buyer rations are similar across regions.'''\n",
    "'''Buyer Ratio.mtw\n",
    "H0:All proportions are equal\n",
    "Ha: Not all Proportions are equal\n",
    "Check p-value\n",
    "If p-Value < alpha, we reject Null Hypothesis\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5577ce97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (2, 5)\n",
      "\n",
      "First Few Rows of the Dataset:\n",
      "  Observed Values  East  West  North  South\n",
      "0           Males    50   142    131     70\n",
      "1         Females   435  1523   1356    750\n",
      "\n",
      "Summary Statistics:\n",
      "             East         West        North       South\n",
      "count    2.000000     2.000000     2.000000    2.000000\n",
      "mean   242.500000   832.500000   743.500000  410.000000\n",
      "std    272.236111   976.514465   866.205807  480.832611\n",
      "min     50.000000   142.000000   131.000000   70.000000\n",
      "25%    146.250000   487.250000   437.250000  240.000000\n",
      "50%    242.500000   832.500000   743.500000  410.000000\n",
      "75%    338.750000  1177.750000  1049.750000  580.000000\n",
      "max    435.000000  1523.000000  1356.000000  750.000000\n",
      "\n",
      "Column Names: ['Observed Values', 'East', 'West', 'North', 'South']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the data\n",
    "file_path = r\"C:\\Users\\Reshma\\OneDrive\\Desktop\\Data science\\Python Assignmet\\Python Assignment files\\day 3\\BuyerRatio.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the shape of the data\n",
    "print(\"Data Shape:\", data.shape)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"\\nFirst Few Rows of the Dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Display the summary statistics of the data\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(data.describe())\n",
    "\n",
    "# Display the list of column names\n",
    "column_names = data.columns.tolist()\n",
    "print(\"\\nColumn Names:\", column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fd82c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Few Rows of the Dataset:\n",
      "  Observed Values  East  West  North  South\n",
      "0           Males    50   142    131     70\n",
      "1         Females   435  1523   1356    750\n",
      "\n",
      "P-value: 0.6603094907091882\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "file_path = r\"C:\\Users\\Reshma\\OneDrive\\Desktop\\Data science\\Python Assignmet\\Python Assignment files\\day 3\\BuyerRatio.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First Few Rows of the Dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Extract observed values from the DataFrame\n",
    "observed_data = data.iloc[:, 1:].values\n",
    "\n",
    "# Chi-squared test\n",
    "chi2_stat, p_value, _, _ = stats.chi2_contingency(observed_data)\n",
    "\n",
    "# Print p-value\n",
    "print(\"\\nP-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18a4fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The p-value for the chi-squared test for independence is approximately \n",
    "0.6603. \n",
    "Since this p-value is greater than the typical significance level of 0.05, \n",
    "we do not have enough evidence to reject the null hypothesis.\n",
    "\n",
    "Conclusion:\n",
    "At a 5% significance level, we fail to reject the null hypothesis. \n",
    "This suggests that there is no significant evidence of a difference \n",
    "in male-female buyer ratios across regions.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd92ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''     TeleCall uses 4 centers around the globe to process customer order \n",
    "forms. They audit a certain %  of the customer order forms. Any error in order\n",
    "form renders it defective and has to be reworked before processing.  \n",
    "The manager wants to check whether the defective %  varies by centre. \n",
    "Please analyze the data at 5% significance level and help the manager \n",
    "draw appropriate inferences\n",
    "\n",
    "Minitab File: CustomerOrderForm.mtw\n",
    " \n",
    "     \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c686cfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (300, 4)\n",
      "\n",
      "First Few Rows of the Dataset:\n",
      "  Phillippines   Indonesia       Malta       India\n",
      "0   Error Free  Error Free   Defective  Error Free\n",
      "1   Error Free  Error Free  Error Free   Defective\n",
      "2   Error Free   Defective   Defective  Error Free\n",
      "3   Error Free  Error Free  Error Free  Error Free\n",
      "4   Error Free  Error Free   Defective  Error Free\n",
      "\n",
      "Summary Statistics:\n",
      "       Phillippines   Indonesia       Malta       India\n",
      "count           300         300         300         300\n",
      "unique            2           2           2           2\n",
      "top      Error Free  Error Free  Error Free  Error Free\n",
      "freq            271         267         269         280\n",
      "\n",
      "Column Names: ['Phillippines', 'Indonesia', 'Malta', 'India']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Corrected file path\n",
    "file_path = r\"C:\\Users\\Reshma\\OneDrive\\Desktop\\Data science\\Python Assignmet\\Python Assignment files\\day 3\\Costomer+OrderForm.csv\"\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the shape of the data\n",
    "print(\"Data Shape:\", data.shape)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"\\nFirst Few Rows of the Dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Display the summary statistics of the data\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(data.describe())\n",
    "\n",
    "# Display the list of column names\n",
    "column_names = data.columns.tolist()\n",
    "print(\"\\nColumn Names:\", column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd6f2cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared Test p-value: 0.6665712150680798\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(index=data['Phillippines'], columns=data['Indonesia'])\n",
    "\n",
    "# Chi-squared test for independence\n",
    "chi2_stat, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the p-value\n",
    "print(\"Chi-squared Test p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befd253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The p-value for the chi-squared test for independence between the Philippines\n",
    "and Indonesia centers is approximately 0.6666. Since this p-value is greater \n",
    "than the typical significance level of 0.05, we do not have enough evidence to\n",
    "reject the null hypothesis.\n",
    "\n",
    "Conclusion:\n",
    "At a 5% significance level, we fail to reject the null hypothesis. \n",
    "This suggests that, based on the data, there is no significant evidence of a\n",
    "difference in defective percentages between the Philippines and Indonesia \n",
    "centers.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1e86d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1006552a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c1f0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
